{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the 'processed_data.csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "df = data[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Stratified Sampling to create train-test split (75:25).\n",
    "Finding accuracies of individual labels using Multinomial Naive Bayes classifier, Logistic Regression\n",
    "\n",
    "Here, experimentation is done for the Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['0']])\n",
    "yarg_list = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "predicted_lol_MNB = [] # Prediction list of lists for MNB for Count Vectorizer\n",
    "predicted_lol_MNB_tf = [] # Prediction list of lists for MNB for TF without IDF\n",
    "predicted_lol_MNB_tfidf = [] # Prediction list of lists for MNB for TF with IDF\n",
    "\n",
    "predicted_lol_LR = [] # Prediction list of lists for LR for Count Vectorizer\n",
    "predicted_lol_LR_tf = [] # Prediction list of lists for LR for TF without IDF\n",
    "predicted_lol_LR_tfidf = [] # Prediction list of lists for LR for TF with IDF\n",
    "\n",
    "predicted_lol_SVM = [] # Prediction list of lists for SVM for Count Vectorizer\n",
    "predicted_lol_SVM_tf = [] # Prediction list of lists for SVM for TF without IDF\n",
    "predicted_lol_SVM_tfidf = [] # Prediction list of lists for SVM for TF with IDF\n",
    "true_labels = []\n",
    "\n",
    "for yarg in yarg_list: # Training over all the labels and making consequent predictions\n",
    "    Y = np.array(df[[yarg]])\n",
    "    XTrain, XTest, YTrain, YTest = train_test_split(X, Y, stratify=Y, test_size=0.25)\n",
    "    true_labels.append(list(YTest.flatten())) #Getting true set of labels\n",
    "    cv = CountVectorizer(ngram_range = (1,2), min_df = 1, max_df = 1)\n",
    "    tf = TfidfTransformer(use_idf = False)\n",
    "    tfidf = TfidfTransformer(use_idf = True)\n",
    "    XTrain_counts = cv.fit_transform(XTrain[:, 0])\n",
    "    XTrain_tf = tf.fit_transform(XTrain_counts)\n",
    "    XTrain_tfidf = tfidf.fit_transform(XTrain_counts)\n",
    "    \n",
    "    XTest_counts = cv.transform(XTest[:, 0])\n",
    "    XTest_tf = tf.transform(XTest_counts)\n",
    "    XTest_tfidf = tfidf.transform(XTest_counts)\n",
    "    \n",
    "    # Multinomial Naive Bayes\n",
    "    classifier_MNB = MultinomialNB(alpha = 0.01).fit(XTrain_counts, YTrain)\n",
    "    classifier_MNB_tf = MultinomialNB(alpha = 0.01).fit(XTrain_tf, YTrain)\n",
    "    classifier_MNB_tfidf = MultinomialNB(alpha = 0.01).fit(XTrain_tfidf, YTrain)\n",
    "    predicted_MNB = classifier_MNB.predict(XTest_counts) # Predictions for MNB with Count Vectorizer\n",
    "    predicted_MNB_tf = classifier_MNB.predict(XTest_tf) # Predictions for MNB with TF\n",
    "    predicted_MNB_tfidf = classifier_MNB.predict(XTest_tfidf) # Predictions for MNB with TF-EDF\n",
    "\n",
    "    predicted_lol_MNB.append(list(predicted_MNB))\n",
    "    predicted_lol_MNB_tf.append(list(predicted_MNB_tf))\n",
    "    predicted_lol_MNB_tfidf.append(list(predicted_MNB_tfidf))\n",
    "\n",
    "    # Logistic Regression\n",
    "    classifier_LR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(XTrain_counts, YTrain)\n",
    "    classifier_LR_tf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(XTrain_tf, YTrain)\n",
    "    classifier_LR_tfidf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(XTrain_tfidf, YTrain)\n",
    "    predicted_LR = classifier_LR.predict(XTest_counts) # Predictions for Logistic Regression with Count Vectorizer\n",
    "    predicted_LR_tf = classifier_LR.predict(XTest_tf) # Predictions for Logistic Regression with TF\n",
    "    predicted_LR_tfidf = classifier_LR.predict(XTest_tfidf) # Predictions for Logistic Regression with TF-IDF\n",
    "\n",
    "    predicted_lol_LR.append(list(predicted_LR))\n",
    "    predicted_lol_LR_tf.append(list(predicted_LR_tf))\n",
    "    predicted_lol_LR_tfidf.append(list(predicted_LR_tfidf))\n",
    "\n",
    "    # Support Vector Machine\n",
    "    classifier_SVM = svm.SVC().fit(XTrain_counts, YTrain)\n",
    "    classifier_SVM_tf = svm.SVC().fit(XTrain_tf, YTrain)\n",
    "    classifier_SVM_tfidf = svm.SVC().fit(XTrain_tfidf, YTrain)\n",
    "    predicted_SVM = classifier_SVM.predict(XTest_counts) # Predictions for SVM with Count Vectorizer\n",
    "    predicted_SVM_tf = classifier_SVM.predict(XTest_tf) # Predictions for SVM with TF\n",
    "    predicted_SVM_tfidf = classifier_SVM.predict(XTest_tfidf) # Predictions for SVM with TF-IDF\n",
    "\n",
    "    predicted_lol_SVM.append(list(predicted_SVM))\n",
    "    predicted_lol_SVM_tf.append(list(predicted_SVM_tf))\n",
    "    predicted_lol_SVM_tfidf.append(list(predicted_SVM_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(predicted_lol_MNB), len(predicted_lol_MNB_tf), len(predicted_lol_MNB_tfidf)) \n",
    "print(len(predicted_lol_MNB[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels1 = list(map(list, zip(*true_labels)))  # Transpose of true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "\n",
    "predicted_output_MNB = [] # List to store predicted outputs as integers\n",
    "predicted_output_MNB_tf = []\n",
    "predicted_output_MNB_tfidf = []\n",
    "\n",
    "for i in range(len(predicted_lol_MNB[0])):\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for j in range(9):\n",
    "        temp1.append(predicted_lol_MNB[j][i])\n",
    "        temp2.append(predicted_lol_MNB_tf[j][i])\n",
    "        temp3.append(predicted_lol_MNB_tfidf[j][i])\n",
    "    predicted_output_MNB.append(temp1)\n",
    "    predicted_output_MNB_tf.append(temp2)\n",
    "    predicted_output_MNB_tfidf.append(temp3)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "predicted_output_LR = [] # List to store predicted outputs as integers\n",
    "predicted_output_LR_tf = []\n",
    "predicted_output_LR_tfidf = []\n",
    "\n",
    "for i in range(len(predicted_lol_LR[0])):\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for j in range(9):\n",
    "        temp1.append(predicted_lol_LR[j][i])\n",
    "        temp2.append(predicted_lol_LR_tf[j][i])\n",
    "        temp3.append(predicted_lol_LR_tfidf[j][i])\n",
    "    predicted_output_LR.append(temp1)\n",
    "    predicted_output_LR_tf.append(temp2)\n",
    "    predicted_output_LR_tfidf.append(temp3)\n",
    "\n",
    "# Support Vector Machine\n",
    "\n",
    "predicted_output_SVM = [] # List to store predicted outputs as integers\n",
    "predicted_output_SVM_tf = []\n",
    "predicted_output_SVM_tfidf = []\n",
    "\n",
    "for i in range(len(predicted_lol_SVM[0])):\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for j in range(9):\n",
    "        temp1.append(predicted_lol_SVM[j][i])\n",
    "        temp2.append(predicted_lol_SVM_tf[j][i])\n",
    "        temp3.append(predicted_lol_SVM_tfidf[j][i])\n",
    "    predicted_output_SVM.append(temp1)\n",
    "    predicted_output_SVM_tf.append(temp2)\n",
    "    predicted_output_SVM_tfidf.append(temp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming Loss = (sum_N(sum_L(xor(T, P)))) / (N * L)\n",
    "\n",
    "N_MNB = []\n",
    "N_MNB_tf = []\n",
    "N_MNB_tfidf = []\n",
    "N_LR = []\n",
    "N_LR_tf = []\n",
    "N_LR_tfidf = []\n",
    "N_SVM = []\n",
    "N_SVM_tf = []\n",
    "N_SVM_tfidf = []\n",
    "\n",
    "for i in range(10250):\n",
    "    L_MNB = 0\n",
    "    L_MNB_tf = 0\n",
    "    L_MNB_tfidf = 0\n",
    "    L_LR = 0\n",
    "    L_LR_tf = 0\n",
    "    L_LR_tfidf = 0\n",
    "    L_SVM = 0\n",
    "    L_SVM_tf = 0\n",
    "    L_SVM_tfidf = 0\n",
    "    \n",
    "    for j in range(9):\n",
    "        if true_labels1[i][j] != predicted_output_MNB[i][j]:\n",
    "            L_MNB += 1\n",
    "        if true_labels1[i][j] != predicted_output_LR[i][j]:\n",
    "            L_LR += 1\n",
    "        if true_labels1[i][j] != predicted_output_SVM[i][j]:\n",
    "            L_SVM += 1\n",
    "        if true_labels1[i][j] != predicted_output_MNB_tf[i][j]:\n",
    "            L_MNB_tf += 1\n",
    "        if true_labels1[i][j] != predicted_output_LR_tf[i][j]:\n",
    "            L_LR_tf += 1\n",
    "        if true_labels1[i][j] != predicted_output_SVM_tf[i][j]:\n",
    "            L_SVM_tf += 1\n",
    "        if true_labels1[i][j] != predicted_output_MNB_tfidf[i][j]:\n",
    "            L_MNB_tfidf += 1\n",
    "        if true_labels1[i][j] != predicted_output_LR_tfidf[i][j]:\n",
    "            L_LR_tfidf += 1\n",
    "        if true_labels1[i][j] != predicted_output_SVM_tfidf[i][j]:\n",
    "            L_SVM_tfidf += 1\n",
    "\n",
    "    N_MNB.append(L_MNB)\n",
    "    N_LR.append(L_LR)\n",
    "    N_SVM.append(L_SVM)\n",
    "    N_MNB_tf.append(L_MNB_tf)\n",
    "    N_LR_tf.append(L_LR_tf)\n",
    "    N_SVM_tf.append(L_SVM_tf)\n",
    "    N_MNB_tfidf.append(L_MNB_tfidf)\n",
    "    N_LR_tfidf.append(L_LR_tfidf)\n",
    "    N_SVM_tfidf.append(L_SVM_tfidf)\n",
    "\n",
    "    \n",
    "hamming_loss_MNB = sum(N_MNB)/ (10250 * 9)\n",
    "hamming_loss_LR = sum(N_LR)/ (10250 * 9)\n",
    "hamming_loss_SVM = sum(N_SVM)/ (10250 * 9)\n",
    "hamming_loss_MNB_tf = sum(N_MNB_tf)/ (10250 * 9)\n",
    "hamming_loss_LR_tf = sum(N_LR_tf)/ (10250 * 9)\n",
    "hamming_loss_SVM_tf = sum(N_SVM_tf)/ (10250 * 9)\n",
    "hamming_loss_MNB_tfidf = sum(N_MNB_tfidf)/ (10250 * 9)\n",
    "hamming_loss_LR_tfidf = sum(N_LR_tfidf)/ (10250 * 9)\n",
    "hamming_loss_SVM_tfidf = sum(N_SVM_tfidf)/ (10250 * 9)\n",
    "\n",
    "print(hamming_loss_MNB, hamming_loss_LR, hamming_loss_SVM)  #Optimal value is zero.\n",
    "print(hamming_loss_MNB_tf, hamming_loss_LR_tf, hamming_loss_SVM_tf)\n",
    "print(hamming_loss_MNB_tfidf, hamming_loss_LR_tfidf, hamming_loss_SVM_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, Recall, F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro-Average and Micro-Average Precision, Recall, F-Score\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "for i in range(9):\n",
    "    # Macro Average\n",
    "    prfs_mnb_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB[i], average='macro') # For MNB with Count Vectorizer\n",
    "    prfs_mnb_tf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB_tf[i], average='macro') # For MNB with TF\n",
    "    prfs_mnb_tfidf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB_tfidf[i], average='macro') # For MNB with TF-IDF\n",
    "\n",
    "    prfs_lr_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_LR[i], average='macro') # For LR with Count Vectorizer\n",
    "    prfs_lr_tf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_LR[i], average='macro') # For LR with TF\n",
    "    prfs_lr_tfidf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_LR[i], average='macro') # For LR with TF-IDF\n",
    "\n",
    "    prfs_svm_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM[i], average='macro') # For SVM with Count Vectorizer\n",
    "    prfs_svm_tf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM[i], average='macro') # For SVM with TF\n",
    "    prfs_svm_tfidf_ma = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM[i], average='macro') # For SVM with TF-IDF\n",
    "\n",
    "    # Micro Average\n",
    "    prfs_mnb_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB[i], average='micro') # For MNB with Count Vectorizer\n",
    "    prfs_mnb_tf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB_tf[i], average='micro') # For MNB with TF \n",
    "    prfs_mnb_tfidf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_MNB_tfidf[i], average='micro') # For MNB with TF-IDF\n",
    "\n",
    "    prfs_lr_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_LR[i], average='micro') # For LR with Count Vectorizer\n",
    "    prfs_lr_tf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_LR_tf[i], average='micro') # For LR with TF\n",
    "    prfs_lr_tfidf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_LR_tfidf[i], average='micro') # For LR with TF-IDF\n",
    "\n",
    "    prfs_svm_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM[i], average='micro') # For SVM with Count Vectorizer\n",
    "    prfs_svm_tf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM_tf[i], average='micro') # For SVM with TF\n",
    "    prfs_svm_tfidf_mi = precision_recall_fscore_support(true_labels[i], predicted_lol_SVM_tfidf[i], average='micro') # For SVM with TF-IDF\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing precision, recall, F-Score\n",
    "\n",
    "print(prfs_mnb_ma, prfs_mnb_tf_ma, prfs_mnb_tfidf_ma)\n",
    "print(prfs_mnb_mi, prfs_mnb_tf_mi, prfs_mnb_tfidf_mi)\n",
    "print(prfs_lr_ma, prfs_lr_tf_ma, prfs_lr_tfidf_ma)\n",
    "print(prfs_lr_mi, prfs_lr_tf_mi, prfs_lr_tfidf_mi)\n",
    "print(prfs_svm_ma, prfs_svm_tf_ma, prfs_svm_tfidf_ma)\n",
    "print(prfs_svm_mi, prfs_svm_tf_mi, prfs_svm_tfidf_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
