{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processed_data.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "652896a62fa318da2871d0d6bd06256ded9af4a4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dc8c4f38a7029b5383aecb5cca040cf6f7062146"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cs.CV</th>\n",
       "      <th>cs.LG</th>\n",
       "      <th>cs.AI</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>cs.CL</th>\n",
       "      <th>cs.NE</th>\n",
       "      <th>cs.IR</th>\n",
       "      <th>math.OC</th>\n",
       "      <th>cs.RO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We propose an architecture for VQA which utili...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent approaches based on artificial neural n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We introduce the multiresolution recurrent neu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multi-task learning is motivated by the observ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We present MILABOT: a deep reinforcement learn...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...    cs.RO\n",
       "0  We propose an architecture for VQA which utili...  ...        0\n",
       "1  Recent approaches based on artificial neural n...  ...        0\n",
       "2  We introduce the multiresolution recurrent neu...  ...        0\n",
       "3  Multi-task learning is motivated by the observ...  ...        0\n",
       "4  We present MILABOT: a deep reinforcement learn...  ...        0\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "82366cc37ed2dd02437c2dac2d245f22edba012e"
   },
   "outputs": [],
   "source": [
    "X = df[\"text\"].values\n",
    "y = df.drop(columns=\"text\").values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "74668eff9a3a280fb1a3aa69daa9b6495c56c6e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "72ef99bcf9463a6cf16f4ff7c787b4b88bfa1be4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, Conv1D, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "0096d1217452f438ce00177fb196999a50179407"
   },
   "outputs": [],
   "source": [
    "max_features = 20000  # number of words we want to keep\n",
    "maxlen = 300  # max length of the comments in the model\n",
    "batch_size = 64  # batch size for the model\n",
    "embedding_dims = 20  # dimension of the hidden variable, i.e. the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "0b2ac38414bbe7736aaa02db12f93921fac97de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32800 train sequences\n",
      "8200 test sequences\n",
      "Average train sequence length: 162\n",
      "Average test sequence length: 163\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "x_train = tokenizer.texts_to_sequences(X_train)\n",
    "x_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "b3990b46fe3cf191b8f26cc4467f032439e8708f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (32800, 300)\n",
      "x_test shape: (8200, 300)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "74e57a8fbcab25505462aafe407725d53a54bf75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100), Dimension(20)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "53d65f8bbcb5824b70493a1725b7eeba6a6d8517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         168,     1,    76,     2,   586,   166,     1,   379,     2,\n",
       "         842,   166,     9,   709,     4,   312,   160,    23,  1031,\n",
       "           1,  1753,   592,   367,    21,   336,   138,   191,   591,\n",
       "         771,     1,   160,    27,   172,   151,   333,     3,  1423,\n",
       "         161,   730,    22,   126,     3,    47,   470,    58,     2,\n",
       "           1,    81,    45,   103,    46,    39,    47,  8853,    19,\n",
       "           1,   998,    49,  1235,    93,     1,    54,  3353,     2,\n",
       "          46,    39,    14,    66,   688,  2901,     5,     1,  6168,\n",
       "           2,     1,    21,   263,    23,   363,   424,    39,  3600,\n",
       "           8,   415,    73,   149,    82,   287,   157,   940,  2651,\n",
       "          13,   341,     2,   328,    21,    10,    14,    63,    55,\n",
       "           5,   864,     1,   312,   160,     5,   821,    80,   341,\n",
       "           2,   328, 11715,     1,    39,    47,     5,     1,   312,\n",
       "         160,     3,     1,   821,  2331,     2,     1,  1102,    21,\n",
       "          72,     6,    12,    28,     7,    50,     4,  1132,    76,\n",
       "          23,   607,   126,    22,   842,   166,    56,  1897,     5,\n",
       "         821,    71,   341,     2,   328,     3,    73,   149,    21,\n",
       "         168,    20,    76,     1,    73,   149,    34,     9,  4860,\n",
       "          16,  4594,    30,    15,   341,     2,   328,    34,     6,\n",
       "           1,   898,     2,   330,   166,   967,     3,  1705,   486,\n",
       "           7,   624,    17,   164,     8,     1,   201,   432,    16,\n",
       "        3555,    80,   842,    15,     4,   245,     6,     4,   496,\n",
       "         187,    36,    11,   207,   345,    21,   224,    38,    10,\n",
       "          20,    39,   877,   140,   291,    41,   918,    39,     6,\n",
       "         166,    73,   149,    21,    72,     4,  1132,    76,     8,\n",
       "         126,    22,   842,   166,     2,   341,     2,   328,     3,\n",
       "          73,   149,    21], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "5a361b843b67177ae09e7d598d1adbf90e551f1b"
   },
   "outputs": [],
   "source": [
    "comment_input = Input((maxlen,))\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "comment_emb = Embedding(max_features, \n",
    "                        embedding_dims, \n",
    "                        input_length=maxlen)(comment_input)\n",
    "cnn1 = Conv1D(filters=50, kernel_size=5, activation='relu')(comment_emb)\n",
    "# we add a GlobalMaxPooling1D, which will extract features from the embeddings\n",
    "# of all words in the comment\n",
    "h = GlobalMaxPooling1D()(cnn1)\n",
    "\n",
    "# We project onto a six-unit output layer, and squash it with a sigmoid:\n",
    "fc1 = Dense(200, activation='relu')(h)\n",
    "d1 = Dropout(0.4)(fc1)\n",
    "output = Dense(9, activation='sigmoid')(d1)\n",
    "\n",
    "model = Model(inputs=comment_input, outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.01),\n",
    "              metrics=['accuracy', \n",
    "                      'categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c2c52bf78176580881e51a06443b4538e4ee503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29520 samples, validate on 3280 samples\n",
      "Epoch 1/10\n",
      " 3136/29520 [==>...........................] - ETA: 4s - loss: 0.1690 - acc: 0.9331 - categorical_accuracy: 0.7567"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "d11e8e1631f0ff7c5ae4c1737b7d29fc6a75c4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0]\n",
      "(8200, 300)\n",
      "[0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "sample = 9\n",
    "print(y_test[sample])\n",
    "print(x_test.shape)\n",
    "print(np.array(model.predict(x_test)[sample]>0.5).astype(int))\n",
    "y_pred = (model.predict(x_test)>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "13b2c90576b8236b3fd1bb96bf8e7eb994c34907"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d94044af5c354065aa7169b6ee662419630fea8"
   },
   "outputs": [],
   "source": [
    "keras.backend.print_tensor(keras.metrics.top_k_categorical_accuracy(y_test, y_pred, k = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88c24accd8e2628e7d5cc68849421b8757d9e150"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14cc1bb707da5b6018d05ca4d14aa5c446e63e97"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
