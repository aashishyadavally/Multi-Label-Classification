{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Powerset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the processed csv file for Label POSET technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data_lp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting counts of the labels in the Label POSET dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = np.array(df[['Class']]).flatten()\n",
    "label_count = list(dict(Counter(df_class)).values())\n",
    "\n",
    "label_count_df = []\n",
    "for i in range(len(label_count)):\n",
    "    temp = [label_count[i]]*label_count[i]\n",
    "    label_count_df.extend(temp)\n",
    "\n",
    "df['Label Count'] = label_count_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Labels which occur only once in the Label Powerset Dataframe as they cannot be futher split into the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Label Count'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Stratified Sampling to create train-test split (75:25). Finding accuracies of POSET labels using Multinomial Naive Bayes classifier, Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['Abstract'])\n",
    "Y = np.array(df['Class'])\n",
    "\n",
    "XTrain, XTest, YTrain, YTest = train_test_split(X, Y, stratify=Y, test_size=0.25) # Getting train and test sets for X and Y\n",
    "cv = CountVectorizer(ngram_range = (1,2), min_df = 1, max_df = 1)\n",
    "tf = TfidfTransformer(use_idf = False)\n",
    "tfidf = TfidfTransformer(use_idf = True)\n",
    "\n",
    "XTrain_counts = cv.fit_transform(XTrain[:])\n",
    "XTrain_tf = tf.fit_transform(XTrain_counts)\n",
    "XTrain_tfidf = tfidf.fit_transform(XTrain_counts)\n",
    "\n",
    "XTest_counts = cv.transform(XTest[:])\n",
    "XTest_tf = tf.transform(XTest_counts)\n",
    "XTest_tfidf = tfidf.transform(XTest_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "classifier_MNB = MultinomialNB(alpha = 0.01).fit(XTrain_counts, YTrain) # Naive Bayes classifier trained on Count Vectorizer\n",
    "classifier_MNB_tf = MultinomialNB(alpha = 0.01).fit(XTrain_tf, YTrain)  # Naive Bayes classifier trained on TF without IDF\n",
    "classifier_MNB_tfidf = MultinomialNB(alpha = 0.01).fit(XTrain_tfidf, YTrain)  # Naive Bayes classifier trained on TF-IDF\n",
    "predicted_MNB = classifier_MNB.predict(XTest_counts)\n",
    "predicted_MNB_tf = classifier_MNB.predict(XTest_tf)\n",
    "predicted_MNB_tfidf = classifier_MNB.predict(XTest_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "classifier_LR = LogisticRegression(random_state=0).fit(XTrain_counts, YTrain)  # Logistic Regression trained on Count Vectorizer\n",
    "classifier_LR_tf = LogisticRegression(random_state=0).fit(XTrain_tf, YTrain)  # Logistic Regression trained on TF without IDF\n",
    "classifier_LR_tfidf = LogisticRegression(random_state=0).fit(XTrain_tfidf, YTrain)  # Logistic Regression trained on TF-IDF\n",
    "predicted_LR = classifier_LR.predict(XTest_counts)\n",
    "predicted_LR_tf = classifier_LR_tf.predict(XTest_tf)\n",
    "predicted_LR_tfidf = classifier_LR_tfidf.predict(XTest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "classifier_SVM = svm.SVC().fit(XTrain_counts, YTrain) # SVM classifier trained on Count Vectorizer\n",
    "classifier_SVM_tf = svm.SVC().fit(XTrain_tf, YTrain) # SVM classifier trained on TF without IDF\n",
    "classifier_SVM_tfidf = svm.SVC().fit(XTrain_tfidf, YTrain) # SVM classifier trained on TF-IDF\n",
    "predicted_SVM = classifier_SVM.predict(XTest_counts)\n",
    "predicted_SVM_tf = classifier_SVM.predict(XTest_tf)\n",
    "predicted_SVM_tfidf = classifier_SVM.predict(XTest_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing accuracies of each classifier\n",
    "\n",
    "print('Accuracy of Multinomial Naive Bayes Classifier: '+ str(classifier_MNB.score(XTest_counts, YTest)))\n",
    "print('Accuracy of Logistic Regression: '+ str(classifier_LR.score(XTest_counts, YTest)))\n",
    "print('Accuracy of Support Vector Machine: '+ str(classifier_SVM.score(XTest_counts, YTest)))\n",
    "print('Accuracy of Multinomial Naive Bayes Classifier with TF: '+ str(classifier_MNB_tf.score(XTest_tf, YTest)))\n",
    "print('Accuracy of Logistic Regression with TF: '+ str(classifier_LR_tf.score(XTest_tf, YTest)))\n",
    "print('Accuracy of Support Vector Machine with TF: '+ str(classifier_SVM_tf.score(XTest_tf, YTest)))\n",
    "print('Accuracy of Multinomial Naive Bayes Classifier with TF-IDF: '+ str(classifier_MNB_tfidf.score(XTest_tfidf, YTest)))\n",
    "print('Accuracy of Logistic Regression with TF-IDF: '+ str(classifier_LR_tfidf.score(XTest_tfidf, YTest)))\n",
    "print('Accuracy of Support Vector Machine with TF-IDF: '+ str(classifier_SVM_tfidf.score(XTest_tfidf, YTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, Recall, F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Macro Average : Output is a tuple (Precision, Recall, F-Score, Support)\n",
    "prfs_mnb_ma = precision_recall_fscore_support(YTest, predicted_MNB, average='macro')\n",
    "prfs_mnb_tf_ma = precision_recall_fscore_support(YTest, predicted_MNB_tf, average='macro')\n",
    "prfs_mnb_tfidf_ma = precision_recall_fscore_support(YTest, predicted_MNB_tfidf, average='macro')\n",
    "\n",
    "prfs_lr_ma = precision_recall_fscore_support(YTest, predicted_LR, average='macro')\n",
    "prfs_lr_tf_ma = precision_recall_fscore_support(YTest, predicted_LR_tf, average='macro')\n",
    "prfs_lr_tfidf_ma = precision_recall_fscore_support(YTest, predicted_LR_tfidf, average='macro')\n",
    "\n",
    "prfs_svm_ma = precision_recall_fscore_support(YTest, predicted_SVM, average='macro')\n",
    "prfs_svm_tf_ma = precision_recall_fscore_support(YTest, predicted_SVM, average='macro')\n",
    "prfs_svm_tfidf_ma = precision_recall_fscore_support(YTest, predicted_SVM, average='macro')\n",
    "\n",
    "# Micro Average : Output is a tuple (Precision, Recall, F-Score, Support)\n",
    "prfs_mnb_mi = precision_recall_fscore_support(YTest, predicted_MNB, average='micro')\n",
    "prfs_mnb_tf_mi = precision_recall_fscore_support(YTest, predicted_MNB_tf, average='micro')\n",
    "prfs_mnb_tfidf_mi = precision_recall_fscore_support(YTest, predicted_MNB, average='micro')\n",
    "\n",
    "prfs_lr_mi = precision_recall_fscore_support(YTest, predicted_LR, average='micro')\n",
    "prfs_lr_tf_mi = precision_recall_fscore_support(YTest, predicted_LR_tf, average='micro')\n",
    "prfs_lr_tfidf_mi = precision_recall_fscore_support(YTest, predicted_LR_tfidf, average='micro')\n",
    "\n",
    "prfs_svm_mi = precision_recall_fscore_support(YTest, predicted_SVM, average='micro')\n",
    "prfs_svm_tf_mi = precision_recall_fscore_support(YTest, predicted_SVM, average='micro')\n",
    "prfs_svm_tfidf_mi = precision_recall_fscore_support(YTest, predicted_SVM, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
